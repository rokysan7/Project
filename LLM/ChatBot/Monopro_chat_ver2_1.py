import streamlit as st
from openai import OpenAI
import os
from datetime import datetime
import pandas as pd
import re


# from dotenv import load_dotenv

# load_dotenv()

# API í‚¤ ì„¤ì •
# OpenAI.api_key = os.getenv('OPENAI_API_KEY')

client = OpenAI(
    api_key = st.secrets['general']['openai_api_key'])

# Log íŒŒì¼ path
LOG_FILE_PATH = 'chat_logs/'

# log file manage
def manage_log_file(session_id):
    today = datetime.now().strftime('%Y-%m-%d')
    log_file = f'{LOG_FILE_PATH}{session_id}_{today}.txt'

    if not os.path.exists(LOG_FILE_PATH):
        os.makedirs(LOG_FILE_PATH)

    if os.path.exists(log_file):
        with open(log_file, 'r', encoding='utf-8') as file:
            conversation = file.read()
    else:
        conversation = ""

    return log_file, conversation

# conversation ì €ì¥ í•¨ìˆ˜
def save_conversation(log_file, messages):
    conversation = ""
    for message in messages:
        if message["role"] == "user":
            conversation += f"User: {message['content']}\n"
        elif message["role"] == "assistant":
            conversation += f"AI: {message['content']}\n"
    with open(log_file, 'w', encoding='utf-8') as file:
        file.write(conversation)

# Session ID ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_id: str):
    if session_id not in st.session_state["store"]:
        st.session_state["store"][session_id] = []
    return st.session_state["store"][session_id]

# ê¸°ì¡´ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
def load_conversation(session_id: str):
    log_file, conversation = manage_log_file(session_id)
    messages = []
    if conversation:
        conversation_lines = conversation.strip().split('\n')
        for line in conversation_lines:
            if line.startswith("User:"):
                messages.append({"role": "user", "content": line[len("User: "):]})
            elif line.startswith("AI:"):
                messages.append({"role": "assistant", "content": line[len("AI: "):]})
    
    return messages

## ê²¬ì ì„œ################################################################################################## 
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build

### êµ¬ê¸€ sheet api setting
SCOPES = ["https://www.googleapis.com/auth/spreadsheets.readonly"]
SAMPLE_SPREADSHEET_ID = "1bCu29AFSt3c5wS1K2uyQ1kvcppi3DtEvOccESucqiYc"
SAMPLE_RANGE_NAME = "ì‹œíŠ¸1!A1:O549"

secrets = st.secrets['general']['openai_api_key']

creds = Credentials(
        st.secrets['google']['token'],
        refresh_token = st.secrets['google']['refresh_token'],
        token_uri = st.secrets['google']['token_uri'],
        client_id = st.secrets['google']['client_id'],
        client_secret = st.secrets['google']['client_secret'],
        scopes = st.secrets['google']['scopes']
    )
creds.refresh(Request())
service = build('sheets', 'v4', credentials=creds)
sheet = service.spreadsheets()
result = sheet.values().get(spreadsheetId=SAMPLE_SPREADSHEET_ID, range=SAMPLE_RANGE_NAME).execute()
values = result.get('values', [])

df = pd.DataFrame(values[1:], columns = values[0])

### ê²¬ì ìš© í•¨ìˆ˜
def normalize_input(text):
    pattern = re.compile(r"(\S+)\s+(\S+)\s+(\d+)ëª…\s+(\d+)ê°œì›”")
    matches = pattern.findall(text)
    
    results = []
    for match in matches:
        product = match[0].strip(' ,')
        license = match[1].strip(' ,')
        users = match[2].strip(' ,')
        months = match[3].strip(' ,')
        results.append((product, license, users, months))
    
    return results

def answer_quote(user_input, filtered_df):
    df_str = filtered_df.to_string(index=False)
    
    PROMPT_TEMPLATE = """
    Role: 
    ë„ˆëŠ” ì—ë“€í…Œí¬ ì œí’ˆì„ retail í•˜ëŠ” 'ëª¨ë…¸í”„ë¡œ'ë¼ëŠ” íšŒì‚¬ì˜ ìƒë‹´ ì§ì›ì´ì•¼.
    
    Instructions:
    - ë„ˆëŠ” ë¬¼ê±´ì˜ ê²¬ì ì„ ê³„ì‚°í•´ì„œ ì•Œë ¤ì£¼ë©´ ë¼.
    - ê²¬ì ì˜ ë‚´ìš©ì€ Product Informationì„ ì² ì €í•˜ê²Œ ë”°ë¥´ë©´ ë¼.
    - ë§Œì•½ 10ê°œ ì´ìƒ êµ¬ì…í•œë‹¤ë©´, í• ì¸ì´ ê°€ëŠ¥í•˜ë‹ˆ ì´ë©”ì¼ë¡œ ìš”ì²­í•´ ë‹¬ë¼ê³  ë§í•´.
    - Product Informationì— ì—†ëŠ” ë‚´ìš©ì„ ê²¬ì  ìš”ì²­ ë°›ëŠ”ë‹¤ë©´ 'ê²¬ì  ì£¼ì‹  ìƒí’ˆì€ ì·¨ê¸‰í•˜ì§€ ì•ŠëŠ” ìƒí’ˆì…ë‹ˆë‹¤. ì €í¬ íšŒì‚¬ë¡œ ì´ë©”ì¼ì„ ë‚¨ê²¨ì£¼ì‹œë©´ í˜‘ì˜ í›„ ë‚©í’ˆ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.' ë¼ê³  ë‹µë³€í•´ì•¼í•´.


    Context:
    - í•­ìƒ ì¹œì ˆí•˜ê²Œ ëª¨ë…¸í”„ë¡œ ì§ì›ìœ¼ë¡œ í–‰ë™í•´ì•¼í•´.
    
    ê²¬ì  ì§ˆë¬¸:
    {user_input}

    Product Information:
    {df_str}
    """
    
    prompt = PROMPT_TEMPLATE.format(user_input = user_input, df_str = df_str)
    
    prompt_messages = [{"role": "system", "content": prompt}]
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=prompt_messages
    )
    
    data = response.choices[0].message.content
    return data

def read_quote(user_input, df):
    
    unique_licenses = df.groupby('í’ˆëª…')['ë¼ì´ì„¼ìŠ¤'].unique().reset_index()
    df_str = unique_licenses.to_string(index=False)


    PROMPT_TEMPLATE = """
    Role: 
    ë„ˆëŠ” ê²¬ì ì„œì˜ ë‚´ìš©ì„ Formatì— ë§ê²Œ ë°˜í™˜í•˜ëŠ” í”„ë¡œê·¸ë¨ì´ì•¼.

    Format:
    - í’ˆëª…(ì˜ì–´), ë¼ì´ì„¼ìŠ¤(ì˜ì–´), ìœ ì €ìˆ˜, ê°œì›”
    - 1ê°œì˜ ì£¼ë¬¸ê±´ìˆ˜ì˜ format example: chatgpt plus 1ëª… 1ê°œì›”
    - 1ê°œ ì´ìƒì˜ ì£¼ë¬¸ê±´ìˆ˜ì˜ format example: chatgpt plus 1ëª… 1ê°œì›”, padlet gold 20ëª… 12ê°œì›”
    - 1ê°œ ì´ìƒì˜ ì£¼ë¬¸ê±´ìˆ˜ì˜ format example: chatgpt plus 1ëª… 1ê°œì›”, padlet gold 20ëª… 12ê°œì›”, craiyon pro 1ëª… 1ê°œì›”

    Instructions:
    - ë¬´ì¡°ê±´ Formatìœ¼ë¡œ ë‹µì„ ë°˜í™˜í•´ì•¼í•´
    - ì‚¬ìš©ìê°€ 'í’ˆëª…'ì„ í•œê¸€ë¡œ ì ëŠ”ë‹¤ë©´ ë„ˆëŠ” Product Informationì— ìˆëŠ” í’ˆëª…(ì˜ì–´)ìœ¼ë¡œ ë²ˆì—­í•´ì„œ ë§í•´.
    - 'ìœ ì €ìˆ˜'ì™€ 'ê°œì›”ìˆ˜'ì˜ default ê°’ì€ '1'ì´ë‹¤.
    - 'ìœ ì €ìˆ˜'ì™€ 'ê°œì›”ìˆ˜'ê°€ ì—†ë‹¤ë©´ default ê°’ì„ ë°˜í™˜í•œë‹¤. 
    - ë§Œì•½ 'í’ˆëª…'ë§Œ ì¡´ì¬í•œë‹¤ë©´ ë„ˆëŠ” Product Informationì— ìˆëŠ” 'ë¼ì´ì„¼ìŠ¤' ë¦¬ìŠ¤íŠ¸ì˜ 0ë²ˆì¨° ì¸ë±ìŠ¤ ê°’ìœ¼ë¡œ 'ë¼ì´ì„¼ìŠ¤'ë¥¼ ë°˜í™˜.
    - Product Informationì— ì—†ëŠ” ë‚´ìš©ì„ ê²¬ì  ìš”ì²­ í•œë‹¤ë©´ 'í’ˆëª…'ì—ëŠ” 'Null', 'ë¼ì´ì„¼ìŠ¤'ë„ 'Null'ì„ ë°˜í™˜í•˜ë©´ ë¼.
    - Format ì´ì™¸ì— ë‹¤ë¥¸ ëŒ€ë‹µì€ ì ˆëŒ€ í•˜ì§€ë§ˆ.
    - ì½¤ë§ˆ(,)ëŠ” êµ¬ë¶„ì„ ìœ„í•´ ê°œì›” ë’¤ì—ë§Œ ì“¸ê²ƒ.
     
 
    ê²¬ì  ì§ˆë¬¸:
    {user_input}

    Product Information:
    {df_str}
    """
    
    prompt = PROMPT_TEMPLATE.format(user_input = user_input, df_str = df_str)
    
    prompt_messages = [{"role": "system", "content": prompt}]
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=prompt_messages
    )
    
    data = response.choices[0].message.content
    return data

def get_products_dataframe(quote, df):
    products_and_licenses = [(item[0], item[1]) for item in quote if item[0] != 'Null' and item[1] != 'Null']
    filtered_df = pd.DataFrame()
    for product, license in products_and_licenses:
        temp_df = df[(df['í’ˆëª…'] == product) & (df['ë¼ì´ì„¼ìŠ¤'] == license)][['í’ˆëª…', 'ë¼ì´ì„¼ìŠ¤', 'ìœ ì €ìˆ˜', 'ê°œì›”ìˆ˜', 'ê°€ê²©', 'ë©”ëª¨']]
        filtered_df = pd.concat([filtered_df, temp_df], ignore_index=True)
    return filtered_df

########################################################################################################


# PROMPT_TEMPLATE ì„¤ì •
PROMPT_TEMPLATE = """
Role:
ë„ˆëŠ” ì—ë“€í…Œí¬ ì œí’ˆì„ retail í•˜ëŠ” 'ëª¨ë…¸í”„ë¡œ'ë¼ëŠ” íšŒì‚¬ì˜ ìƒë‹´ ì§ì›ì´ì•¼.

Instructions:
ë‹¤ìŒì€ ëª¨ë…¸í”„ë¡œ ì œí’ˆì˜ ê¸°ë³¸ ê°€ì´ë“œì•¼.
'''
[íŒ¨ë“¤ë ›]
ìŠ¤ì¿¨ ìœ ë£Œìš”ê¸ˆì œ: 12ê°œì›” ë¼ì´ì„¼ìŠ¤, 10 ìœ ì €
í”Œë˜í‹°ë„˜: 12ê°œì›” ë¼ì´ì„¼ìŠ¤, 1 ìœ ì €
[ì±—ì§€í”¼í‹°]
íŒ€: ë‹¤ìˆ˜ ìœ ì €, 12ê°œì›” ì´ìš©ê¶Œ
í”ŒëŸ¬ìŠ¤: 1 ìœ ì €, nê°œì›” ì´ìš©ê¶Œ
[ìœ íŠœë¸Œ]
í”„ë¦¬ë¯¸ì—„: 1 ìœ ì €, 12ê°œì›” ì´ìš©ê¶Œ
[í‚¤ë„¤ë§ˆìŠ¤í„°]
í”„ë¦¬ë¯¸ì—„: 1 ìœ ì €, 12ê°œì›” ì´ìš©ê¶Œ
[ëª¨ì…˜ ì—˜ë¦¬ë¨¼ì¸ ]
ìœ ë£Œ ìš”ê¸ˆì œ: 1 ìœ ì €, 12ê°œì›” ì´ìš©ê¶Œ
[ì½”ìŠ¤í˜ì´ì‹œìŠ¤]
í”„ë¡œ + VR/AR ë¨¸ì§€íë¸Œ: ì„ ìƒë‹˜ 1 + í•™ìƒ n, 12ê°œì›” ë¼ì´ì„¼ìŠ¤
[ì–´ë„ë¹„]
í¬ë¦¬ì—ì´í‹°ë¸Œ í´ë¼ìš°ë“œ ì˜¬ ì•± êµì‚¬ìš©: 1 ìœ ì €, 12ê°œì›” ì´ìš©ê¶Œ
ê³µí†µ FAQ
ê³„ì • ë‚©í’ˆ: ì‹ ê·œ ê³„ì • ìƒì„±, ëª¨ë…¸í”„ë¡œ ì›¹ë©”ì¼ ì´ìš©
ì´ë©”ì¼ ì¸ì¦: ëª¨ë…¸í”„ë¡œ ì›¹ë©”ì¼ë¡œ 6ìë¦¬ í™•ì¸
ëŒ€ëŸ‰êµ¬ë§¤: ìƒí•œ ì—†ìŒ
ë‚©í’ˆ ì†Œìš”ì‹œê°„: 1-3ì¼, ìµœëŒ€ 1ì£¼ì¼
ê³„ì • ê³µìœ : ë¶ˆê°€, 1ì¸ 1ê³„ì • ì›ì¹™
ê¸°íƒ€ ì—ë“€í…Œí¬ ìƒí’ˆ: í˜„ì¬ 10ì¢…, ì¶”ê°€ ìš”ì²­ ê°€ëŠ¥
ì‚¬ìš© ê¸°ê°„: ë‚©í’ˆì¼ë¡œë¶€í„° 1ë…„
ê³„ì • ì—°ì¥: ì¬êµ¬ë§¤ í›„ ì—°ì¥ ì²˜ë¦¬
ì±—GPT FAQ
í”ŒëŸ¬ìŠ¤ ê³„ì • ì—°ì¥: ë¶ˆê°€, ë³´ì•ˆ ë¬¸ì œ
íŒ€ê³¼ í”ŒëŸ¬ìŠ¤ ì°¨ì´: íŒ€ì€ ìš°ì„ ê¶Œ, ìœ ì—°í•œ ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥
íŒ€ ê³„ì • ë‚©í’ˆ: ê´€ë¦¬ì ê³„ì •ê³¼ íŒ€ì› ì—°ê²°
ë¹„ìš© ì°¨ì´: ëŒ€ëŸ‰ êµ¬ë§¤ ëŒ€í–‰, í™˜ìœ¨ ë³€ë™ ë°©ì–´
íŒ¨ë“¤ë › FAQ
í”Œë˜í‹°ë„˜ ê³„ì • ì—°ì¥: ë¶ˆê°€, ë³´ì•ˆ ë¬¸ì œ
ìŠ¤ì¿¨ ê³„ì • ì—°ì¥: ê°€ëŠ¥, ëŒ€ì‹œë³´ë“œ ì œê³µ
ë‚©í’ˆ ì†Œìš”ì‹œê°„: ì„±ìˆ˜ê¸° 1-2ì£¼, í‰ì‹œ 3ì¼
ìœ íŠœë¸Œ FAQ
ì‚¬ìš© ì¸ì›: 1ì¸ 1ê³„ì •, 2ê°œ ë””ë°”ì´ìŠ¤ ë™ì‹œ ì‚¬ìš© ê°€ëŠ¥
ë¹„ìš©: ì•ˆì •ì  ì‚¬ìš©ì„ ìœ„í•œ ë¹„ìš© ì†Œìš”
ì½”ìŠ¤í˜ì´ì‹œìŠ¤ FAQ
ì¶”ê°€ ì˜µì…˜: ì¶”í›„ ì„¸ë¶„í™” ì˜ˆì •
ì–´ë„ë¹„ FAQ
ì‚¬ìš© ì¸ì›: 1ì¸ 1ê³„ì •, 2ê°œ ë””ë°”ì´ìŠ¤ ë™ì‹œ ì‚¬ìš© ê°€ëŠ¥
ìˆ˜ëŸ‰ ì œí•œ: ê¸°ê´€ë‹¹ 1ê°œ ì œí•œ, í•´ê²° ë°©ì•ˆ ëª¨ìƒ‰ ì¤‘
í‚¤ë„¤ë§ˆìŠ¤í„° FAQ
ì‚¬ìš© ì¸ì›: 1ì¸ 1ê³„ì •, 2ê°œ ë””ë°”ì´ìŠ¤ ì‚¬ìš© ê°€ëŠ¥
í™œì„±í™” ë°©ë²•: í™œì„±í™” í‚¤ ë° ë©”ë‰´ì–¼ ì œê³µ
í™œì„±í™” ê¸°í•œ: 1ê°œì›” ë‚´ í™œì„±í™”, ì´í›„ 1ë…„ ì‚¬ìš©
'''
ë„ˆëŠ” ê°€ì´ë“œë¥¼ ë”°ë¼ì„œ ìƒë‹´ì„ ì§„í–‰í•´ ì£¼ë©´ ë¼.


Context:
- ëŒ€í™”ì˜ ë§¥ë½: ë„ˆëŠ” ê°€ì´ë“œì— ì—†ëŠ” ë‚´ìš©ì„ ì§ˆë¬¸ ë°›ëŠ”ë‹¤ë©´ 'ì§ˆë¬¸ ì£¼ì‹  ë‚´ìš©ì€ ë…¼ì˜ê°€ í•„ìš”í•œ ë‚´ìš©ì…ë‹ˆë‹¤. ì €í¬ íšŒì‚¬ë¡œ ì´ë©”ì¼ì„ ë‚¨ê²¨ì£¼ì‹œë©´ í˜‘ì˜ í›„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.' ë¼ê³  ë‹µë³€í•´ì•¼í•´.
- í•­ìƒ ì¹œì ˆí•˜ê²Œ ëª¨ë…¸í”„ë¡œ ì§ì›ìœ¼ë¡œ í–‰ë™í•´ì•¼í•´.

Question:
{question}
"""
# st.set_page_config ëŠ” í•­ìƒ ë§¨ ìœ„ì— ë¶ˆëŸ¬ì™€ì•¼í•¨
st.set_page_config(page_title="MonoPro", page_icon="ğŸ˜ƒ")
 
# Streamlit ì¸í„°í˜ì´ìŠ¤ ë‚´ì—ì„œ í˜¸ì¶œ
user_input = st.text_input("ê²¬ì ìš”ì²­: ")
if st.button("ê²¬ì  ìš”ì²­"):
    response = answer_quote(user_input, get_products_dataframe(normalize_input(read_quote(user_input, df)), df)) # ê²¬ì ì„œ
    st.write(response)

# Streamlit Setting

st.title("Monopro ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
st.info('''ëª¨ë…¸í”„ë¡œ ê³ ê° ìƒë‹´ì‚¬ë¡€ 1,000ê±´ì´ í•™ìŠµëœ ë´‡ ì…ë‹ˆë‹¤.
ê°„ë‹¨í•œ ì§ˆì˜ë¡œ ì‹ ì†í•œ ìƒë‹´ì„ ë°›ì•„ë³´ì„¸ìš”.
ê²¬ì ìš”ì²­: https://monopro.kr/contact
(ì±—ë´‡ ê¸°ë°˜ ìë™ ê²¬ì ì„œ ë°œí–‰ì€ ì¶”í›„ ì§€ì› ì˜ˆì •ì…ë‹ˆë‹¤. )

ë¬¸ì˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ?''')


# CSS ì¶”ê°€ - ì…ë ¥ë€ì„ ê³ ì •í•˜ê¸° ìœ„í•´
st.markdown("""
    <style>
    .fixed-bottom {
        position: fixed;
        bottom: 0;
        width: 100%;
        background: white;
        padding: 10px;
        box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.1);
    }
    </style>
    """, unsafe_allow_html=True)

# ì˜ˆì‹œ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
example_questions = [
    "ëª¨ë…¸í”„ë¡œëŠ” ì–´ë–¤ íšŒì‚¬ì¸ê°€ìš”?",
    "ì·¨ê¸‰í•˜ëŠ” ìƒí’ˆì€ ì–´ë–¤ê²ƒì´ ìˆë‚˜ìš”?",
    "ì£¼ë¬¸ì„ ë„£ê³ ì‹¶ì€ë° ì–´ë–»ê²Œ í•˜ë©´ ë˜ì£ ?"
]

# ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ ìƒì„±
st.subheader("ë¬¸ì˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
for question in example_questions:
    if st.button(question):
        st.session_state["user_input"] = question  

# message ì´ˆê¸°í™”ë¡œ ì‹œì‘
if "messages" not in st.session_state:
    st.session_state["messages"] = []

with st.sidebar:
    session_id = st.text_input("Session ID", value="user0001")

    load_btn = st.button("ì´ì „ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°")
    if load_btn:
        st.session_state["messages"] = load_conversation(session_id)

    clear_btn = st.button("ëŒ€í™”ê¸°ë¡ ì§€ìš°ê¸°")
    if clear_btn:
        st.session_state["messages"] = []
        st.rerun()

    # ëŒ€í™” ë¡œê·¸ ì‚­ì œ ë²„íŠ¼ 
    delete_log_btn = st.button("ëŒ€í™” ë¡œê·¸ ì‚­ì œí•˜ê¸°")
    if delete_log_btn:
        log_file, _ = manage_log_file(session_id)
        if os.path.exists(log_file):
            os.remove(log_file)
            st.success(f"{session_id} ì„¸ì…˜ì˜ ëŒ€í™” ë¡œê·¸ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

# ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜
def print_messages():
    for message in st.session_state["messages"]:
        if message["role"] == "user":
            st.chat_message("human").write(message["content"])
        elif message["role"] == "assistant":
            st.chat_message("ai").write(message["content"])

print_messages()


# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if "user_input" not in st.session_state:
    st.session_state["user_input"] = ""

# ì…ë ¥ì°½ì„ í•­ìƒ í‘œì‹œí•˜ê³ , ê°’ì´ ìˆìœ¼ë©´ í•´ë‹¹ ê°’ì„ ì‚¬ìš©
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
if st.session_state["user_input"]:
    user_input = st.session_state["user_input"]
    st.session_state["user_input"] = ""  # ì´í›„ì— ì¬ì‚¬ìš©ì„ ìœ„í•´ ì´ˆê¸°í™”

if user_input:
    st.chat_message("human").write(f"{user_input}")
    st.session_state["messages"].append({"role": "user", "content": user_input})

    with st.chat_message("ai"):

        # PROMPT TEMPLATE ì ìš©
        prompt = [{"role": "system", "content": PROMPT_TEMPLATE.format(question=user_input)}]

        for message in st.session_state["messages"]:
            prompt.append({"role": message["role"], "content": message["content"]})

        prompt.append({"role": "user", "content": user_input})

        response = client.chat.completions.create(
            model = "gpt-4o",
            messages = prompt,
            stream=True,  # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ í™œì„±í™”
        )

        # ìŠ¤íŠ¸ë¦¬ë° ì—†ì´ ëŒ€ë‹µ ìƒì„±(ì •ìƒ ì‘ë™)
        # ai_response = response.choices[0].message.content
        # st.session_state["messages"].append({"role": "assistant", "content": ai_response})
        # st.write(ai_response)

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë°›ì„ ìë¦¬í‘œì‹œì ìƒì„±
        response_placeholder = st.empty()
        full_response = ""
     
        for chunk in response:
            content = chunk.choices[0].delta.content or ""
            full_response += f'{content}'
            response_placeholder.markdown(full_response)   # ì´ê²Œ í•µì‹¬. ìë¦¿ìˆ˜ë¥¼ ë§ˆí¬ë‹¤ìš´ í•´ì¤˜ì•¼ í•œë‹¤.       
    
        st.session_state["messages"].append({"role": "assistant", "content": full_response})
    
    # conversation ë¡œê·¸íŒŒì¼ì— ì €ì¥
    log_file, _ = manage_log_file(session_id)
    save_conversation(log_file, st.session_state["messages"])

# st.session_state




# patch note
# 1. streaming ê¸°ëŠ¥ ì¶”ê°€
# 2. ê²¬ì ì„œ ê¸°ëŠ¥ ì¶”ê°€
