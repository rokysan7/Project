import streamlit as st
from openai import OpenAI
import os
from datetime import datetime
import pandas as pd
from quote import normalize_input, read_quote, answer_quote, get_products_dataframe

# from dotenv import load_dotenv

# load_dotenv()

# API í‚¤ ì„¤ì •
# OpenAI.api_key = os.getenv('OPENAI_API_KEY')

client = OpenAI(
    api_key = st.secrets['general']['openai_api_key'])

# Log íŒŒì¼ path
LOG_FILE_PATH = 'chat_logs/'

# log file manage
def manage_log_file(session_id):
    today = datetime.now().strftime('%Y-%m-%d')
    log_file = f'{LOG_FILE_PATH}{session_id}_{today}.txt'

    if not os.path.exists(LOG_FILE_PATH):
        os.makedirs(LOG_FILE_PATH)

    if os.path.exists(log_file):
        with open(log_file, 'r', encoding='utf-8') as file:
            conversation = file.read()
    else:
        conversation = ""

    return log_file, conversation

# conversation ì €ì¥ í•¨ìˆ˜
def save_conversation(log_file, messages):
    conversation = ""
    for message in messages:
        if message["role"] == "user":
            conversation += f"User: {message['content']}\n"
        elif message["role"] == "assistant":
            conversation += f"AI: {message['content']}\n"
    with open(log_file, 'w', encoding='utf-8') as file:
        file.write(conversation)

# Session ID ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_id: str):
    if session_id not in st.session_state["store"]:
        st.session_state["store"][session_id] = []
    return st.session_state["store"][session_id]

# ê¸°ì¡´ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
def load_conversation(session_id: str):
    log_file, conversation = manage_log_file(session_id)
    messages = []
    if conversation:
        conversation_lines = conversation.strip().split('\n')
        for line in conversation_lines:
            if line.startswith("User:"):
                messages.append({"role": "user", "content": line[len("User: "):]})
            elif line.startswith("AI:"):
                messages.append({"role": "assistant", "content": line[len("AI: "):]})
    
    return messages

# # ê²¬ì ì„œ 
df = pd.read_excel('Project/LLM/ChatBot/quote.xlsx')

# ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
# quote_text = ""
# for index, row in df.iterrows():
#     quote_text += f"{row['ì œí’ˆëª…']}ì˜ ë‹¨ê°€ëŠ” {row['ë‹¨ê°€']}ì›ì…ë‹ˆë‹¤.\n"

def get_estimate_response(question, quote_dict):
    import re
    match = re.search(r"(\D+)\s*(\d+)\s*ê°œ", question)
    if match:
        product_name = match.group(1).strip()
        quantity = int(match.group(2))
        
        # ì œí’ˆì— í•´ë‹¹í•˜ëŠ” ë‹¨ê°€ë¥¼ ì°¾ìŒ
        if product_name in quote_dict:
            unit_price = quote_dict[product_name]
            total_price = unit_price * quantity
            return f"{product_name}ì˜ {quantity}ê°œì˜ ê²¬ì ì€ {total_price}ì›ì…ë‹ˆë‹¤."
        else:
            return "í•´ë‹¹ ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    else:
        return "ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

# PROMPT_TEMPLATE ì„¤ì •
PROMPT_TEMPLATE = """
Role:
ë„ˆëŠ” ì—ë“€í…Œí¬ ì œí’ˆì„ retail í•˜ëŠ” 'ëª¨ë…¸í”„ë¡œ'ë¼ëŠ” íšŒì‚¬ì˜ ìƒë‹´ ì§ì›ì´ì•¼.

Instructions:
ë‹¤ìŒì€ ëª¨ë…¸í”„ë¡œ ì œí’ˆì˜ ê¸°ë³¸ ê°€ì´ë“œì•¼.
'''
[íŒ¨ë“¤ë ›]
ìŠ¤ì¿¨ ìœ ë£Œìš”ê¸ˆì œ: 12ê°œì›” ë¼ì´ì„¼ìŠ¤, 10 ìœ ì €
í”Œë˜í‹°ë„˜: 12ê°œì›” ë¼ì´ì„¼ìŠ¤, 1 ìœ ì €
[ì±—ì§€í”¼í‹°]
íŒ€: ë‹¤ìˆ˜ ìœ ì €, 12ê°œì›” ì´ìš©ê¶Œ
í”ŒëŸ¬ìŠ¤: 1 ìœ ì €, nê°œì›” ì´ìš©ê¶Œ
[ìœ íŠœë¸Œ]
í”„ë¦¬ë¯¸ì—„: 1 ìœ ì €, 12ê°œì›” ì´ìš©ê¶Œ
[í‚¤ë„¤ë§ˆìŠ¤í„°]
í”„ë¦¬ë¯¸ì—„: 1 ìœ ì €, 12ê°œì›” ì´ìš©ê¶Œ
[ëª¨ì…˜ ì—˜ë¦¬ë¨¼ì¸ ]
ìœ ë£Œ ìš”ê¸ˆì œ: 1 ìœ ì €, 12ê°œì›” ì´ìš©ê¶Œ
[ì½”ìŠ¤í˜ì´ì‹œìŠ¤]
í”„ë¡œ + VR/AR ë¨¸ì§€íë¸Œ: ì„ ìƒë‹˜ 1 + í•™ìƒ n, 12ê°œì›” ë¼ì´ì„¼ìŠ¤
[ì–´ë„ë¹„]
í¬ë¦¬ì—ì´í‹°ë¸Œ í´ë¼ìš°ë“œ ì˜¬ ì•± êµì‚¬ìš©: 1 ìœ ì €, 12ê°œì›” ì´ìš©ê¶Œ
ê³µí†µ FAQ
ê³„ì • ë‚©í’ˆ: ì‹ ê·œ ê³„ì • ìƒì„±, ëª¨ë…¸í”„ë¡œ ì›¹ë©”ì¼ ì´ìš©
ì´ë©”ì¼ ì¸ì¦: ëª¨ë…¸í”„ë¡œ ì›¹ë©”ì¼ë¡œ 6ìë¦¬ í™•ì¸
ëŒ€ëŸ‰êµ¬ë§¤: ìƒí•œ ì—†ìŒ
ë‚©í’ˆ ì†Œìš”ì‹œê°„: 1-3ì¼, ìµœëŒ€ 1ì£¼ì¼
ê³„ì • ê³µìœ : ë¶ˆê°€, 1ì¸ 1ê³„ì • ì›ì¹™
ê¸°íƒ€ ì—ë“€í…Œí¬ ìƒí’ˆ: í˜„ì¬ 10ì¢…, ì¶”ê°€ ìš”ì²­ ê°€ëŠ¥
ì‚¬ìš© ê¸°ê°„: ë‚©í’ˆì¼ë¡œë¶€í„° 1ë…„
ê³„ì • ì—°ì¥: ì¬êµ¬ë§¤ í›„ ì—°ì¥ ì²˜ë¦¬
ì±—GPT FAQ
í”ŒëŸ¬ìŠ¤ ê³„ì • ì—°ì¥: ë¶ˆê°€, ë³´ì•ˆ ë¬¸ì œ
íŒ€ê³¼ í”ŒëŸ¬ìŠ¤ ì°¨ì´: íŒ€ì€ ìš°ì„ ê¶Œ, ìœ ì—°í•œ ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥
íŒ€ ê³„ì • ë‚©í’ˆ: ê´€ë¦¬ì ê³„ì •ê³¼ íŒ€ì› ì—°ê²°
ë¹„ìš© ì°¨ì´: ëŒ€ëŸ‰ êµ¬ë§¤ ëŒ€í–‰, í™˜ìœ¨ ë³€ë™ ë°©ì–´
íŒ¨ë“¤ë › FAQ
í”Œë˜í‹°ë„˜ ê³„ì • ì—°ì¥: ë¶ˆê°€, ë³´ì•ˆ ë¬¸ì œ
ìŠ¤ì¿¨ ê³„ì • ì—°ì¥: ê°€ëŠ¥, ëŒ€ì‹œë³´ë“œ ì œê³µ
ë‚©í’ˆ ì†Œìš”ì‹œê°„: ì„±ìˆ˜ê¸° 1-2ì£¼, í‰ì‹œ 3ì¼
ìœ íŠœë¸Œ FAQ
ì‚¬ìš© ì¸ì›: 1ì¸ 1ê³„ì •, 2ê°œ ë””ë°”ì´ìŠ¤ ë™ì‹œ ì‚¬ìš© ê°€ëŠ¥
ë¹„ìš©: ì•ˆì •ì  ì‚¬ìš©ì„ ìœ„í•œ ë¹„ìš© ì†Œìš”
ì½”ìŠ¤í˜ì´ì‹œìŠ¤ FAQ
ì¶”ê°€ ì˜µì…˜: ì¶”í›„ ì„¸ë¶„í™” ì˜ˆì •
ì–´ë„ë¹„ FAQ
ì‚¬ìš© ì¸ì›: 1ì¸ 1ê³„ì •, 2ê°œ ë””ë°”ì´ìŠ¤ ë™ì‹œ ì‚¬ìš© ê°€ëŠ¥
ìˆ˜ëŸ‰ ì œí•œ: ê¸°ê´€ë‹¹ 1ê°œ ì œí•œ, í•´ê²° ë°©ì•ˆ ëª¨ìƒ‰ ì¤‘
í‚¤ë„¤ë§ˆìŠ¤í„° FAQ
ì‚¬ìš© ì¸ì›: 1ì¸ 1ê³„ì •, 2ê°œ ë””ë°”ì´ìŠ¤ ì‚¬ìš© ê°€ëŠ¥
í™œì„±í™” ë°©ë²•: í™œì„±í™” í‚¤ ë° ë©”ë‰´ì–¼ ì œê³µ
í™œì„±í™” ê¸°í•œ: 1ê°œì›” ë‚´ í™œì„±í™”, ì´í›„ 1ë…„ ì‚¬ìš©
'''
ë„ˆëŠ” ê°€ì´ë“œë¥¼ ë”°ë¼ì„œ ìƒë‹´ì„ ì§„í–‰í•´ ì£¼ë©´ ë¼.


Context:
- ëŒ€í™”ì˜ ë§¥ë½: ë„ˆëŠ” ê°€ì´ë“œì— ì—†ëŠ” ë‚´ìš©ì„ ì§ˆë¬¸ ë°›ëŠ”ë‹¤ë©´ 'ì§ˆë¬¸ ì£¼ì‹  ë‚´ìš©ì€ ë…¼ì˜ê°€ í•„ìš”í•œ ë‚´ìš©ì…ë‹ˆë‹¤. ì €í¬ íšŒì‚¬ë¡œ ì´ë©”ì¼ì„ ë‚¨ê²¨ì£¼ì‹œë©´ í˜‘ì˜ í›„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.' ë¼ê³  ë‹µë³€í•´ì•¼í•´.
- í•­ìƒ ì¹œì ˆí•˜ê²Œ ëª¨ë…¸í”„ë¡œ ì§ì›ìœ¼ë¡œ í–‰ë™í•´ì•¼í•´.

Question:
{question}
"""
# st.set_page_config ëŠ” í•­ìƒ ë§¨ ìœ„ì— ë¶ˆëŸ¬ì™€ì•¼í•¨
st.set_page_config(page_title="MonoPro", page_icon="ğŸ˜ƒ")
 
# Streamlit ì¸í„°í˜ì´ìŠ¤ ë‚´ì—ì„œ í˜¸ì¶œ
user_input = st.text_input("ê²¬ì ìš”ì²­: ")
if st.button("ê²¬ì  ìš”ì²­"):
    response = answer_quote(user_input, get_products_dataframe(normalize_input(read_quote(user_input, df)), df)) # ê²¬ì ì„œ
    st.write(response)

# Streamlit Setting

st.title("Monopro ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
st.info('''ëª¨ë…¸í”„ë¡œ ê³ ê° ìƒë‹´ì‚¬ë¡€ 1,000ê±´ì´ í•™ìŠµëœ ë´‡ ì…ë‹ˆë‹¤.
ê°„ë‹¨í•œ ì§ˆì˜ë¡œ ì‹ ì†í•œ ìƒë‹´ì„ ë°›ì•„ë³´ì„¸ìš”.
ê²¬ì ìš”ì²­: https://monopro.kr/contact
(ì±—ë´‡ ê¸°ë°˜ ìë™ ê²¬ì ì„œ ë°œí–‰ì€ ì¶”í›„ ì§€ì› ì˜ˆì •ì…ë‹ˆë‹¤. )

ë¬¸ì˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ?''')


# CSS ì¶”ê°€ - ì…ë ¥ë€ì„ ê³ ì •í•˜ê¸° ìœ„í•´
st.markdown("""
    <style>
    .fixed-bottom {
        position: fixed;
        bottom: 0;
        width: 100%;
        background: white;
        padding: 10px;
        box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.1);
    }
    </style>
    """, unsafe_allow_html=True)

# ì˜ˆì‹œ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
example_questions = [
    "ëª¨ë…¸í”„ë¡œëŠ” ì–´ë–¤ íšŒì‚¬ì¸ê°€ìš”?",
    "ì·¨ê¸‰í•˜ëŠ” ìƒí’ˆì€ ì–´ë–¤ê²ƒì´ ìˆë‚˜ìš”?",
    "ì£¼ë¬¸ì„ ë„£ê³ ì‹¶ì€ë° ì–´ë–»ê²Œ í•˜ë©´ ë˜ì£ ?"
]

# ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ ìƒì„±
st.subheader("ë¬¸ì˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
for question in example_questions:
    if st.button(question):
        st.session_state["user_input"] = question  

# message ì´ˆê¸°í™”ë¡œ ì‹œì‘
if "messages" not in st.session_state:
    st.session_state["messages"] = []

with st.sidebar:
    session_id = st.text_input("Session ID", value="user0001")

    load_btn = st.button("ì´ì „ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°")
    if load_btn:
        st.session_state["messages"] = load_conversation(session_id)

    clear_btn = st.button("ëŒ€í™”ê¸°ë¡ ì§€ìš°ê¸°")
    if clear_btn:
        st.session_state["messages"] = []
        st.rerun()

    # ëŒ€í™” ë¡œê·¸ ì‚­ì œ ë²„íŠ¼ 
    delete_log_btn = st.button("ëŒ€í™” ë¡œê·¸ ì‚­ì œí•˜ê¸°")
    if delete_log_btn:
        log_file, _ = manage_log_file(session_id)
        if os.path.exists(log_file):
            os.remove(log_file)
            st.success(f"{session_id} ì„¸ì…˜ì˜ ëŒ€í™” ë¡œê·¸ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

# ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜
def print_messages():
    for message in st.session_state["messages"]:
        if message["role"] == "user":
            st.chat_message("human").write(message["content"])
        elif message["role"] == "assistant":
            st.chat_message("ai").write(message["content"])

print_messages()


# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if "user_input" not in st.session_state:
    st.session_state["user_input"] = ""

# ì…ë ¥ì°½ì„ í•­ìƒ í‘œì‹œí•˜ê³ , ê°’ì´ ìˆìœ¼ë©´ í•´ë‹¹ ê°’ì„ ì‚¬ìš©
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
if st.session_state["user_input"]:
    user_input = st.session_state["user_input"]
    st.session_state["user_input"] = ""  # ì´í›„ì— ì¬ì‚¬ìš©ì„ ìœ„í•´ ì´ˆê¸°í™”

if user_input:
    st.chat_message("human").write(f"{user_input}")
    st.session_state["messages"].append({"role": "user", "content": user_input})

    with st.chat_message("ai"):

        # PROMPT TEMPLATE ì ìš©
        prompt = [{"role": "system", "content": PROMPT_TEMPLATE.format(question=user_input)}]

        for message in st.session_state["messages"]:
            prompt.append({"role": message["role"], "content": message["content"]})

        prompt.append({"role": "user", "content": user_input})

        response = client.chat.completions.create(
            model = "gpt-4o",
            messages = prompt,
            stream=True,  # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ í™œì„±í™”
        )

        # ìŠ¤íŠ¸ë¦¬ë° ì—†ì´ ëŒ€ë‹µ ìƒì„±(ì •ìƒ ì‘ë™)
        # ai_response = response.choices[0].message.content
        # st.session_state["messages"].append({"role": "assistant", "content": ai_response})
        # st.write(ai_response)

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë°›ì„ ìë¦¬í‘œì‹œì ìƒì„±
        response_placeholder = st.empty()
        full_response = ""
     
        for chunk in response:
            content = chunk.choices[0].delta.content or ""
            full_response += f'{content}'
            response_placeholder.markdown(full_response)   # ì´ê²Œ í•µì‹¬. ìë¦¿ìˆ˜ë¥¼ ë§ˆí¬ë‹¤ìš´ í•´ì¤˜ì•¼ í•œë‹¤.       
    
        st.session_state["messages"].append({"role": "assistant", "content": full_response})
    
    # conversation ë¡œê·¸íŒŒì¼ì— ì €ì¥
    log_file, _ = manage_log_file(session_id)
    save_conversation(log_file, st.session_state["messages"])

# st.session_state




# patch note
# 1. streaming ê¸°ëŠ¥ ì¶”ê°€
# 2. ê²¬ì ì„œ ê¸°ëŠ¥ ì¶”ê°€
